{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNN8pg3XUZX0"
   },
   "source": [
    "# LSTM for lyric classification Poopy vs Bodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1727,
     "status": "ok",
     "timestamp": 1734437251530,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "WsCSQwjnURQL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1734437271239,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "UMx_0xaQUiMn"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./bodo_poopy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KoJvT8PVLzS"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1734437271239,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "1-9q-zn1VX5R",
    "outputId": "589d6baf-d97a-46a3-94bc-5a17247b3741"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 156,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45,\n        \"min\": 0,\n        \"max\": 155,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          96,\n          69,\n          82\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"poopy\",\n          \"bodo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 63,\n        \"samples\": [\n          \"ZANDRY \\r\\nAlbum \\\"Mifameno\\\" - Ao\\u00fbt 2003\\n\\r\\nAndroany ianao no tratry ny faha-enim-bolana\\r\\nMibadabada, mitehaka, miantso an\\u2019I Dada\\r\\nKa faly I Dada (02)\\r\\nHatramin\\u2019izay moa dia ny nonon\\u2019i Neny\\r\\nNo nankafizinao sy nahazatra anao \\u00f4 ry Zandry a!\\n\\n\\r\\nAndroany amin\\u2019izay dia hiova ny fomba fiainanao\\r\\nManomboka miampy izao ny fivelomanao\\r\\nHitombo ny sakafo mba hivelaranao\\r\\nHahita tsiron-javam-baovao\\r\\nToy ny kobam-bary, ovy nopotserina\\r\\nTotom-boanjo, patsa,\\r\\nTrondro sy anana\\r\\nHena sy legioma sy voan-kazo koa\\r\\nAnkafihizo fa soa ho anao\\n\\n\\r\\nAza manahy ianao rehefa hatory\\r\\nSatria ny nonon-dreny tsy hajanona akory\\r\\nFa hitohy, sy mbola ho ela\\r\\nIreny rehetra ireny no omena anao\\r\\nSatria tian\\u2019I Neny Hitombo saina sy vatana ianao\\r\\nAry ho salama\\n\\r\\nAndroany amin\\u2019izay dia hiova ny fomba fiainanao\\r\\nManomboka miampy izao ny fivelomanao\\r\\nHitombo ny sakafo mba hivelaranao\\r\\nHahita tsiron-javam-baovao\\r\\nToy ny kobam-bary, ovy nopotserina\\r\\nTotom-boanjo, patsa,\\r\\nTrondro sy anana\\r\\nHena sy legioma sy voan-kazo koa\\r\\nAnkafihizo fa soa ho anao\\n\\n\\r\\nOmeo sakafo ny zaza\\r\\nFa feno enim-bolana ny zaza\\r\\nOmeo sakafo ny zanakao\\r\\nFa feno enim-bolana ny zanakao\\n\\r\\nAuteur: Poopy / Tovo\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0 \\r\\nCompositeur: Naivo        --------\",\n          \"Variana, variana mijery\\r\\nNy fombafomabn\\u2019ny hafa\\r\\nTavela, tavela irery\\r\\nNilaozan\\u2019ny omby niahaka\\r\\nFa ny tany miodina ihany\\r\\nMandalo, mandalo ny fiainana\\r\\nLany andro mitsikera\\r\\nNy an\\u2019ny tena tsy hita\\n\\r\\nHo aiza, ho aiza\\r\\nNo tena be fitrena\\r\\nNy l\\u00e0lana anefa iray\\r\\nAlao mora fa sao mora tola\\r\\nNy aina tsy roa fa iray\\n\\r\\nMalama, malama ny l\\u00e0lana\\r\\nKanefa ianao tsy mijery\\r\\nNy mety, ny mety hifaharana\\r\\nKa indro fa potrak\\u2019irery\\r\\nFa ny andro misosa ihany\\r\\nNy resaka anie tsy ho lany\\r\\nIzay vita toa tsy hita\\r\\nFa mitakoritsika ihany\\n\\r\\nhttp://www.multimania.com/schmilblik/malagasyrainb.html        --------\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "dataset"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-09c1cc94-b3b1-4177-ba75-018dca238898\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>Sasa-miandry azy eo ianao\\r\\nAngamba izy efa l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bodo</td>\n",
       "      <td>Afaka ny Tahotro,\\nVoafidy ankehitriny\\nTsy mb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bodo</td>\n",
       "      <td>Ny fitiavantsika roa\\r\\nKanto tokoa\\r\\nNofinof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>bodo</td>\n",
       "      <td>Ambarambarao amin'ny dada\\nAmbarambarao amin'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>bodo</td>\n",
       "      <td>Dia kotsan-dranomaso indray\\r\\nNy tavako andra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09c1cc94-b3b1-4177-ba75-018dca238898')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-09c1cc94-b3b1-4177-ba75-018dca238898 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-09c1cc94-b3b1-4177-ba75-018dca238898');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-2d1f3d48-bfc3-4440-aee4-1f3ba012707f\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d1f3d48-bfc3-4440-aee4-1f3ba012707f')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-2d1f3d48-bfc3-4440-aee4-1f3ba012707f button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Unnamed: 0 Label                                               text\n",
       "0           0  bodo  Sasa-miandry azy eo ianao\\r\\nAngamba izy efa l...\n",
       "1           1  bodo  Afaka ny Tahotro,\\nVoafidy ankehitriny\\nTsy mb...\n",
       "2           2  bodo  Ny fitiavantsika roa\\r\\nKanto tokoa\\r\\nNofinof...\n",
       "3           3  bodo  Ambarambarao amin'ny dada\\nAmbarambarao amin'n...\n",
       "4           4  bodo  Dia kotsan-dranomaso indray\\r\\nNy tavako andra..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1734437271239,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "pqh40BCdVQPP",
    "outputId": "01de5775-93b5-4f71-9975-78ece25dfe3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 747,
     "status": "ok",
     "timestamp": 1734437278131,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "1wngNGWWVcZx",
    "outputId": "20de6cf4-36d8-43b9-98df-492d067f912f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels inside are:  ['bodo' 'poopy']\n"
     ]
    }
   ],
   "source": [
    "print(\"The labels inside are: \", dataset['Label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734437278541,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "2jtLP4rUVG-3",
    "outputId": "28b9ac2e-da5d-4d4f-fce8-1030c8778e9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "Label         0\n",
      "text          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# looking for empty or null row\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1734437281410,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "hBqnQ8MVVxL3",
    "outputId": "1479e9d1-c385-4eba-b1d6-3b72409c919c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156 entries, 0 to 155\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  156 non-null    int64 \n",
      " 1   Label       156 non-null    object\n",
      " 2   text        156 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j28iVN4kWSri"
   },
   "source": [
    "The data does not show any empty or irrelevant element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBxSp1vPYO6U"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3539,
     "status": "ok",
     "timestamp": 1734437287859,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "F4iQ8vRTYqBY",
    "outputId": "6257af86-3dd7-4015-8871-25285411a8f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
      "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.26.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.3.0->torchtext) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.2)\n",
      "Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchtext\n",
      "Successfully installed torchtext-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext sentencepiece\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXYKGr66aYnR"
   },
   "source": [
    "Because we are using malagasy-based dataset, for sure, there are very few of pre-trained word embeddings, this is why we are to use the method of \"sentencePiece\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 9837,
     "status": "ok",
     "timestamp": 1734437297693,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "TyM-fgquWQeX"
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from torchtext.data.utils import get_tokenizer\n",
    "#from torchtext.vocab import FastText\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1734438340528,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "uTtci1CRkPLB"
   },
   "outputs": [],
   "source": [
    "# splitting the dataset into train and test and only using the train dataset to even build the vocabulary\n",
    "X = dataset['text'].tolist()\n",
    "y = dataset['Label'].tolist()\n",
    "X_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1734437297694,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "GZjOapa1aAgW",
    "outputId": "0c838370-08b0-4fb7-84b9-e5c10c8d35e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Sasa-miandry azy eo ianao\\r\\nAngamba izy efa l...   \n",
      "1  Afaka ny Tahotro,\\nVoafidy ankehitriny\\nTsy mb...   \n",
      "2  Ny fitiavantsika roa\\r\\nKanto tokoa\\r\\nNofinof...   \n",
      "3  Ambarambarao amin'ny dada\\nAmbarambarao amin'n...   \n",
      "4  Dia kotsan-dranomaso indray\\r\\nNy tavako andra...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  sasamiandry azy eo ianao\\r\\nangamba izy efa la...  \n",
      "1  afaka ny tahotro\\nvoafidy ankehitriny\\ntsy mba...  \n",
      "2  ny fitiavantsika roa\\r\\nkanto tokoa\\r\\nnofinof...  \n",
      "3  ambarambarao aminny dada\\nambarambarao aminny ...  \n",
      "4  dia kotsandranomaso indray\\r\\nny tavako andrao...  \n"
     ]
    }
   ],
   "source": [
    "# Simple text cleaning function\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'text' column in your dataframe\n",
    "dataset['cleaned_text'] = dataset['text'].apply(clean_text)\n",
    "\n",
    "# Show the cleaned text\n",
    "print(dataset[['text', 'cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1734437297694,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "KEchq9FPfbgj"
   },
   "outputs": [],
   "source": [
    "# Save the cleaned text to a temporary file\n",
    "with open('corpus.txt', 'w', encoding='utf-8') as f:\n",
    "    for text in dataset['cleaned_text']:\n",
    "        f.write(text + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1734437372024,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "X6LBWPwsgW18"
   },
   "outputs": [],
   "source": [
    "# Train the SentencePiece model\n",
    "spm.SentencePieceTrainer.train(input='corpus.txt', model_prefix='mymodel', vocab_size=1500, character_coverage=0.9995)\n",
    "\n",
    "# The two files created: mymodel.model and mymodel.vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUh0FPuBhwv_"
   },
   "source": [
    "We are to use this model for tokenization of the training and the test data with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 653,
     "status": "ok",
     "timestamp": 1734437743174,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "KAatCUkvhqUS",
    "outputId": "e96e7a97-be11-4a3a-fd30-405faf579322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        cleaned_text  \\\n",
      "0  sasamiandry azy eo ianao\\r\\nangamba izy efa la...   \n",
      "1  afaka ny tahotro\\nvoafidy ankehitriny\\ntsy mba...   \n",
      "2  ny fitiavantsika roa\\r\\nkanto tokoa\\r\\nnofinof...   \n",
      "3  ambarambarao aminny dada\\nambarambarao aminny ...   \n",
      "4  dia kotsandranomaso indray\\r\\nny tavako andrao...   \n",
      "\n",
      "                                      tokenized_text  \n",
      "0  [1324, 1404, 6, 302, 3, 78, 14, 209, 173, 67, ...  \n",
      "1  [714, 3, 4, 1217, 8, 858, 663, 6, 868, 3, 5, 2...  \n",
      "2  [3, 4, 1292, 169, 1192, 106, 10, 1066, 330, 28...  \n",
      "3  [498, 1060, 8, 92, 4, 266, 498, 1060, 8, 92, 4...  \n",
      "4  [19, 3, 20, 99, 103, 294, 1397, 98, 3, 4, 978,...  \n"
     ]
    }
   ],
   "source": [
    "# Load the trained SentencePiece model\n",
    "sp = spm.SentencePieceProcessor(model_file='mymodel.model')\n",
    "\n",
    "# Tokenize the cleaned text from the DataFrame\n",
    "dataset['tokenized_text'] = dataset['cleaned_text'].apply(lambda x: sp.encode_as_ids(x))\n",
    "\n",
    "# Display the tokenized text\n",
    "print(dataset[['cleaned_text', 'tokenized_text']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaVk9uxVjDMM"
   },
   "source": [
    "Here, we are to padd for the sequences to have thhe same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1734437821617,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "yoUl3rZdgr_I",
    "outputId": "166d4f1a-a5dd-47f4-eb10-3a6abb27191a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1324, 1404,    6,  ...,    0,    0,    0],\n",
      "        [ 714,    3,    4,  ...,    0,    0,    0],\n",
      "        [   3,    4, 1292,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 857,  470,  493,  ...,    0,    0,    0],\n",
      "        [ 282,  219,  738,  ...,    0,    0,    0],\n",
      "        [  24,  561,   15,  ...,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Pad the sequences to make sure they all have the same length\n",
    "tokenized_data = [torch.tensor(seq) for seq in dataset['tokenized_text']]\n",
    "padded_data = pad_sequence(tokenized_data, batch_first=True, padding_value=0)  # Padding value can be 0\n",
    "\n",
    "# Print padded sequences\n",
    "print(padded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1734439043422,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "GW8fybr1nycv",
    "outputId": "8e260220-62b6-434b-84f9-0f65ff07864a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), Shape: torch.Size([156])\n"
     ]
    }
   ],
   "source": [
    "#label one-hot encodeer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the labels\n",
    "encoded_labels = label_encoder.fit_transform(dataset['Label'])\n",
    "\n",
    "# Convert to a PyTorch tensor\n",
    "labels = torch.tensor(encoded_labels)\n",
    "\n",
    "# Print the shape and unique values\n",
    "print(f\"Encoded labels: {labels}, Shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 666,
     "status": "ok",
     "timestamp": 1734439777685,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "GmSmPFcQjTuy"
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    padded_data,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1734440122416,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "S5Elyjo9r6TR",
    "outputId": "7eb90c75-47dc-4170-d426-802e9e0e78c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([124, 419])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1734440146161,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "3UspOXrVsCrA",
    "outputId": "c1707717-2d45-4914-fb84-f369d3b190b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 419])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1734439806559,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "rOQipVb8qrBh"
   },
   "outputs": [],
   "source": [
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1734439829046,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "5pmKdYuVqyCW"
   },
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = LyricsDataset(X_train, y_train)\n",
    "val_dataset = LyricsDataset(X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734439830294,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "lJQ7PMfdq0p7"
   },
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1734439952444,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "2MiUXwvcrUSv"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(outputs, labels):\n",
    "    # Get predicted class by finding the max logit\n",
    "    _, predicted = torch.max(outputs, dim=1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    accuracy = correct / labels.size(0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 119977,
     "status": "error",
     "timestamp": 1734440873791,
     "user": {
      "displayName": "Kaleba Andriamanaja",
      "userId": "07048414623636893092"
     },
     "user_tz": -180
    },
    "id": "i0QMKEdoq1mq",
    "outputId": "efd88a5a-c6d2-4e39-bb94-3e2d2950f7b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.6883, Train Acc: 0.5391, Val Loss: 0.6731, Val Acc: 0.6250\n",
      "Epoch 2/10, Train Loss: 0.6850, Train Acc: 0.5792, Val Loss: 0.6577, Val Acc: 0.6250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-0285aa0a9257>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example LSTM model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, 128)  # Input vocab size\n",
    "        self.lstm = nn.LSTM(128, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # Embedding layer\n",
    "        _, (hidden, _) = self.lstm(x)  # Use the hidden state from LSTM\n",
    "        out = self.fc(hidden[-1])     # Pass through a fully connected layer\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 1500  # Vocabulary size from SentencePiece\n",
    "hidden_size = 128\n",
    "output_size = len(set(labels.tolist()))  # Number of unique labels (classes)\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "num_layers = 3\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = LSTMClassifier(input_size, hidden_size, output_size, num_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "\n",
    "    # Training\n",
    "\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track training loss and accuracy\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += calculate_accuracy(outputs, batch_labels)\n",
    "\n",
    "    # Average loss and accuracy for training\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_features, val_labels in val_loader:\n",
    "            val_outputs = model(val_features)\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "            val_accuracy += calculate_accuracy(val_outputs, val_labels)\n",
    "\n",
    "    # Average loss and accuracy for validation\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy /= len(val_loader)\n",
    "\n",
    "    # Print metrics for this epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saOIecQHrZYY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNOr1CSDwLlorrpq4povx60",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
